{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Method of Moments for Mixture Models and Hidden Markov Models\n",
    "\n",
    "by A. Anandkumar, D. Hsu, and S.M. Kakade\n",
    "http://arxiv.org/abs/1203.0683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Warm-up: bag-of-words topic modeling\n",
    "- Setup:\n",
    "    - A document is a bag of words.\n",
    "    - A document belongs to a single topic.\n",
    "    - The words in a document are drawn i.i.d. from a multinomial distribution corresponding to the document's topic.\n",
    "    - There are $k$ topics.\n",
    "    - There are $d$ words.\n",
    "    - Each document contains $\\ell \\geq 3$ words.\n",
    "- Generative process for a document:\n",
    "    - Document's topic $h$ is drawn from a multinomial distribution specified by $\\vec{w} \\in \\Delta^{k-1}$\n",
    "    $$ \\Pr [h=j] = w_j $$\n",
    "    where\n",
    "    $j\\in [k]$\n",
    "    - Given the topic $h$, the document's $\\ell$ words are drawn from the multinomial distribution $\\vec{\\mu}_h\\in\\Delta^{d-1}$. Each word in the document is represented by a one-hot random vector $\\vec{x}_v = \\vec{e}_i$ (\"the $v$-th word in the document is $i$\").\n",
    "        - For each word $v \\in [\\ell]$ in the document, the conditional probabilty of the word given the topic is:\n",
    "        $$ \\Pr[\\vec{x}_v = \\vec{e}_i | h=j] = \\langle \\vec{e}_i,\\vec{\\mu}_j \\rangle = M_{i,j}$$\n",
    "        where\n",
    "            - $i \\in [d]$\n",
    "            - $j \\in [k]$\n",
    "            - $M \\equiv [\\vec{\\mu_1} | \\vec{\\mu_2} | \\cdots | \\vec{\\mu_k} ] \\in \\mathbb{R}^{d \\times k}$\n",
    "    - Non-degeneracy conditions:\n",
    "        - $w_j>0 \\forall j \\in [k]$\n",
    "        - $\\text{rank}(M)=k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pairwise and triple-wise probabilities:\n",
    "    - $\\text{Pairs}_{i,j} \\equiv \\Pr [\\vec{x}_1 = \\vec{e}_i, \\vec{x}_2 = \\vec{e}_j]$\n",
    "    - $\\text{Triples}_{i,j,k} \\equiv \\Pr [\\vec{x}_1 = \\vec{e}_i, \\vec{x}_2 = \\vec{e}_j,\\vec{x}_3 = \\vec{e}_k]$\n",
    "    - We can also view $\\text{Pairs}$ and $\\text{Triples}$ as expectations of tensor products of the random vectors:\n",
    "        - $\\text{Pairs}_{i,j} = \\mathbb{E} [\\vec{x}_1 \\otimes \\vec{x}_2] $\n",
    "        - $\\text{Triples}_{i,j} = \\mathbb{E} [\\vec{x}_1 \\otimes \\vec{x}_2 \\otimes \\vec{x}_3] $\n",
    "    - We can also view $\\text{Triples}$ as the following linear operator:\n",
    "        - $\\text{Triples} : \\mathbb{R}^d \\to \\mathbb{R}^{d\\times d}$\n",
    "        - $\\text{Triples} : \\vec{\\eta} \\mapsto \\mathbb{E}[(\\vec{x}_1 \\otimes \\vec{x}_2) \\langle \\vec{\\eta} , \\vec{x}_3 \\rangle]$\n",
    "        - $\\text{Triples}(\\vec{\\eta})_{i,j} = \\sum_{x=1}^d \\vec{\\eta}_x \\text{Triples}_{i,j,x} = \\sum_{x=1}^d \\vec{\\eta}_x \\text{Triples}(\\vec{e}_x)_{i,j}$\n",
    "    - We can now write $\\text{Pairs}$ and $\\text{Triples}$ in terms of the model parameters $M$ and $\\vec{w}$, since $\\vec{x}_1,\\vec{x}_2,\\vec{x}_3$ are conditionally dependent given $h$\n",
    "        - $\\text{Pairs} = M \\text{diag}(\\vec{w}) M^T$\n",
    "        - $\\text{Triples}(\\vec{\\eta}) = M \\text{diag}(M^T \\vec{\\eta}) \\text{diag}(\\vec{w}) M^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observable operators and their spectral peroperties\n",
    "- [revisit!]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm A:\n",
    "1. Estimate $\\widehat{\\text{Pairs}}\\in \\mathbb{R}^{d \\times d}$ and $\\widehat{\\text{Triples}} \\in \\mathbb{R}^{d \\times d \\times d}$\n",
    "2. Compute truncated SVD of $\\widehat{\\text{Pairs}}$\n",
    "    - Let $\\hat{U} \\in \\mathbb{R}^{d \\times k}$ be the left singular vectors of $\\widehat{\\text{Pairs}}$ corresponding to its top $k$ singular values\n",
    "    - Let $\\hat{V} \\in \\mathbb{R}^{d \\times k}$ be the right singular vectors of $\\widehat{\\text{Pairs}}$ corresponding to its top $k$ singular values\n",
    "3. Pick $\\vec{\\eta}\\in \\mathbb{R}^d$\n",
    "    - Select randomly from $\\text{range}(\\hat{U})$, e.g. by:\n",
    "        - $\\vec{\\eta} \\leftarrow \\hat{U} \\vec{\\theta}$, where\n",
    "            - $\\theta \\in \\mathbb{R}^k$ is a random unit vector distributed uniformly over $\\mathcal{S}^{k-1}$\n",
    "4. Compute the observable operator $\\hat{B}(\\vec{\\eta}) \\equiv (\\hat{U}^T \\widehat{\\text{Triples}}(\\vec{\\eta}) \\hat{V})(\\hat{U}^T \\widehat{\\text{Pairs}} \\hat{V})^{-1}$\n",
    "5. Compute right eigenvectors $\\hat{\\xi}_1,\\hat{\\xi}_2,\\dots,\\hat{\\xi}_k$ of $\\hat{B}(\\vec{\\eta})$\n",
    "6. For each $j \\in [k]$, let $$\\hat{\\mu}_j \\equiv \\frac{\\hat{U} \\hat{\\xi}_j}{\\langle \\vec{1},\\hat{U} \\hat{\\xi}_j \\rangle} $$\n",
    "7. Return $\\hat{M} \\equiv [\\hat{\\mu_1} | \\hat{\\mu_2} | \\cdots | \\hat{\\mu_k} ]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pairwise_probabilities(X):\n",
    "    return X.T.dot(X)\n",
    "    \n",
    "def triplewise_probabilities(X):\n",
    "    # inefficient, will revisit later\n",
    "    return sum([np.einsum('i,j,k->ijk',x,x,x) for x in X])\n",
    "    \n",
    "def uniformly_sample_unit_sphere(k):\n",
    "    ''' \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    k : int\n",
    "        Dimensionality of sphere\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    theta : (k,), numpy.ndarray\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    X = npr.rand(k)-0.5\n",
    "    norm = np.sqrt(np.sum(X**2))\n",
    "    theta = X / norm\n",
    "    return theta\n",
    "    \n",
    "\n",
    "def create_triples_operator(triples):\n",
    "    \n",
    "    '''\n",
    "    Represent a third-order tensor of triple-wise probabilities as a linear operator\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    triples : (d,d,d), numpy.ndarray\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    triples_operator : (d,k), numpy.ndarray\n",
    "        each column represents a topic by a vector of word probabilities,\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    def triples_operator(eta):\n",
    "        '''  '''\n",
    "        return sum([triples[:,:,i]*eta[i] for i in range(len(eta))])\n",
    "    \n",
    "    return triples_operator\n",
    "\n",
    "def algorithm_A(pairs,triples,k):\n",
    "    '''\n",
    "    Given low-order moments, recover mixture probabilities\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pairs : (d,d), numpy.ndarray\n",
    "    \n",
    "    triples : (d,d,d), numpy.ndarray\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    M : (d,k), numpy.ndarray\n",
    "        each column represents a topic by a vector of word probabilities,\n",
    "        \n",
    "    '''\n",
    "    d = len(pairs)\n",
    "    \n",
    "    # truncated svd of pairs\n",
    "    U,s,V = np.linalg.svd(pairs)\n",
    "    U_hat = U[:,:k]\n",
    "    V_hat = V[:,:k]\n",
    "    \n",
    "    \n",
    "    # pick eta from range(U_hat) in R^d\n",
    "    theta = uniformly_sample_unit_sphere(k)\n",
    "    eta = U_hat.dot(theta)\n",
    "    \n",
    "    # compute value of observable operator\n",
    "    triples_operator = create_triples_operator(triples)\n",
    "    oo_eta = np.dot( U_hat.T.dot(triples_operator(eta)).dot(V_hat), np.linalg.inv(U_hat.T.dot(pairs).dot(V_hat)))\n",
    "    \n",
    "    # compute top-k right eigenvectors of oo_eta\n",
    "    # evals,evecs=np.linalg.eigh(oo_eta) \n",
    "    evals,evecs = scipy.linalg.eigh(oo_eta)\n",
    "    \n",
    "    # compute mu's\n",
    "    mus = [U_hat.dot(evec) for evec in evecs.T]\n",
    "    mus = [mu/np.sum(mu) for mu in mus]\n",
    "\n",
    "    # concatenate and return M\n",
    "    M = np.vstack(mus).T\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d=100\n",
    "k=10\n",
    "U_hat = npr.rand(d,k)\n",
    "evecs = npr.rand(d,k)\n",
    "evec = evecs[:,0]\n",
    "U_hat.dot(evec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# computing low-order moments of temporally ordered data\n",
    "\n",
    "# generic, e.g. continuous valued vectors or one-hot-encoded discrete variables\n",
    "def onestep_probabilities(X):\n",
    "    return sum([np.einsum('i,j->ij',X[i],X[i+1]) for i in xrange(len(X)-1)])\n",
    "    \n",
    "def twostep_probabilities(X):\n",
    "    return sum([np.einsum('i,j,k->ijk',X[i],X[i+1],X[i+2]) for i in xrange(len(X)-2)])\n",
    "\n",
    "\n",
    "# specific to lists of discrete trajectories\n",
    "def discrete_onestep_probabilities(dtrajs):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dtrajs : list of array-like\n",
    "        each element in dtrajs is a flat list/array of integers\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    P_12 : (d,d), numpy.ndarray\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    d = np.max(np.hstack(dtrajs))+1\n",
    "    P_12 = np.zeros((d,d))\n",
    "    \n",
    "    for traj in dtrajs:\n",
    "        for i in xrange(len(traj)-1):\n",
    "            P_12[traj[i],traj[i+1]] += 1\n",
    "    \n",
    "    return P_12 / len(np.hstack(dtrajs))\n",
    "    \n",
    "def discrete_twostep_probabilities(dtrajs):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dtrajs : list of array-like\n",
    "        each element in dtrajs is a flat list/array of integers\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    P_123 : (d,d,d), numpy.ndarray\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    d = np.max(np.hstack(dtrajs))+1\n",
    "    P_123 = np.zeros((d,d,d))\n",
    "    \n",
    "    for traj in dtrajs:\n",
    "        for i in xrange(len(traj)-2):\n",
    "            P_123[traj[i],traj[i+1],traj[i+2]] += 1\n",
    "            \n",
    "    return P_123 / len(np.hstack(dtrajs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible errors in method of moments paper:\n",
    "- 3.3 Algorithm B: should be $P_{1,3} \\in R^{d\\times d}$, not $P_{1,3} \\in R^{k \\times k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_rotation_matrix(k):\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def algorithm_B(P_12, P_13, P_123, k):\n",
    "    ''' \n",
    "    \n",
    "    General method of moments estimator.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    P_12 : (d,d), numpy.ndarray\n",
    "        Empirical average of tensor product of x_1 and x_2, (x_1 \\otimes x_2)\n",
    "        \n",
    "    P_13 : (d,d), numpy.ndarray\n",
    "        Empirical average of tensor product of x_1 and x_3, (x_1 \\otimes x_3)\n",
    "        \n",
    "    P_123 : (d,d,d), numpy.ndarray\n",
    "        Empirical average of tensor product of x_1, x_2, and x_3, (x_1 \\otimes x_2 \\otimes x_3)\n",
    "        \n",
    "    k : int\n",
    "        number of latent mixture components\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    M_3 : (d,k), numpy.ndarray\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # check inputs are compatible shapes\n",
    "    d = len(P_12)\n",
    "    assert(P_12.shape==(d,d))\n",
    "    assert(P_13.shape==(d,d))\n",
    "    assert(P_123.shape==(d,d,d))\n",
    "    assert(k<=d)\n",
    "    \n",
    "    \n",
    "    # compute top-k left and right singular vectors of P_12\n",
    "    U1,_,U2=np.linalg.svd(P_12)\n",
    "    U1 = U1[:,:k]\n",
    "    U2 = U2[:,:k]\n",
    "    \n",
    "    # compute top-k right singular vectors of P_13\n",
    "    _,_,U3=np.linalg.svd(P_13)\n",
    "    U3 = U3[:,:k]\n",
    "    \n",
    "    # pick invertible theta\n",
    "    theta = sample_rotation_matrix(k)\n",
    "    \n",
    "    # form B_123(U3 theta[0])\n",
    "    B_123 = (U1.T.dot(P_123).dot(U3.dot(theta[0])).dot(U2)).dot(np.linalg.inv(U1.T.dot(P_12).dot(U_2)))\n",
    "    \n",
    "    # compute R1 that diagonalizes B_123(U3 theta[0])\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # form matrix L\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    # form and return M3\n",
    "    M3 = U3.dot(np.linalg.inv(theta)).dot(L)\n",
    "    return M3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-view mixture models\n",
    "- General setting:\n",
    "    - $k$ is the number mixture components\n",
    "    - $\\ell \\geq 3$ is the number of views\n",
    "    - $\\vec{w} \\in \\Delta^{k-1}$ is a vector of mixing weights\n",
    "    - $h$ is a discrete hidden random variable, with $\\Pr[h=j]=w_j$ for all $j \\in [k]$\n",
    "    - $\\vec{x}_1,\\dots,\\vec{x}_\\ell \\in \\mathbb{R}^d$ are $\\ell$ random vectors conditionally independent given $h$\n",
    "    - The conditional mean vectors are:\n",
    "    $$\\vec{\\mu}_{v,j} \\equiv \\mathbb{E}[\\vec{x}_v | h=j]$$\n",
    "    where\n",
    "        - $v \\in [\\ell]$\n",
    "        - $ j \\in [k]$\n",
    "    - Let $M_v \\equiv [\\vec{\\mu}_{v,1} | \\vec{\\mu}_{v,2} | \\cdots | \\vec{\\mu}_{v,k} ] \\in \\mathbb{R}^{d\\times k}$\n",
    "        - Note: we don't specify anything else about the distributions of $\\vec{x}_v$, and they can be continuous, discrete, or hybrid\n",
    "- Non-degeneracy conditions:\n",
    "    - $w_j > 0$ for $j \\in [k]$\n",
    "    - $\\text{rank}(M_v)=k$ for $v \\in [\\ell]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observable moments and operators\n",
    "- $P_{1,2}$\n",
    "- $P_{1,2,3}$\n",
    "- $B_{1,2,3}(\\vec{\\eta}) = (U_1^T M_1) \\text{diag} (M_3^T \\vec{\\eta}) (U_1^T M_1)^{-1} $ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm B: general estimation procedure\n",
    "1. Compute empirical averages to form $\\hat{P}_{1,2}$, $\\hat{P}_{1,3}$, and $\\hat{P}_{1,2,3}$\n",
    "2. Compute $\\hat{U}_1$\n",
    "3. Compute $\\hat{U}_2$\n",
    "4. Compute $\\hat{U}_3$\n",
    "5. Pick invertible matrix $\\Theta$\n",
    "    - E.g. a random rotation matrix\n",
    "6. Form $\\hat{B}_{1,2,3}$\n",
    "7. Diagonalize $\\hat{B}_{1,2,3}$\n",
    "8. Form the matrix $\\hat{L}$\n",
    "9. Return $\\hat{M}_3 \\equiv \\hat{U}_3 \\Theta^{-1} \\hat{L}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An HMM is an instance of a 3-view mixture model:\n",
    "- $\\vec{x}_1,\\vec{x}_2,\\vec{x}_3$ are conditionally independent given $h_2$\n",
    "- Parameters of three-view mixture model on $(h,\\vec{x}_1,\\vec{x}_2,\\vec{x}_3)$ are:\n",
    "    - $\\vec{w} \\equiv T \\hat{\\pi}$\n",
    "    - $M_1 \\equiv O \\text{diag}(\\vec{\\pi}) T^T \\text{diag} (T \\vec{pi})^{-1}$\n",
    "    - $M_2 \\equiv O$\n",
    "    - $M_3 \\equiv OT$\n",
    "- $B_{3,1,2}(\\vec{\\eta}) = (U_3^T O T ) \\text{diag}(O^T\\vec{\\eta}) (U_3^T O T)^{-1}$\n",
    "- The HMM parameters are then given by:\n",
    "    - Transition matrix: $T = (U_3^T O)^{-1} R$, where\n",
    "        - $R$ is the matrix of right eigenvectors of $B_{3,1,2}(\\vec{\\eta})$\n",
    "    - Conditional mean matrix: $O$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a random instance\n",
    "npr.seed(0)\n",
    "k = 10  # number of topics\n",
    "d = 100 # number of words\n",
    "\n",
    "# distribution over topics\n",
    "w = npr.rand(k)\n",
    "w /= np.sum(w)\n",
    "\n",
    "# conditional distributions over words, given topics\n",
    "M = npr.rand(d,k)\n",
    "M /= M.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "d=100\n",
    "k=10\n",
    "U = npr.rand(d,k)\n",
    "V = npr.rand(d,k)\n",
    "pairs = npr.rand(d,d)\n",
    "triples = npr.rand(d,d,d)\n",
    "eta = npr.rand(d)\n",
    "\n",
    "def triples_operator(triples,eta):\n",
    "    return sum([triples[:,:,i]*eta[i] for i in range(len(eta))])\n",
    "\n",
    "triples_eta = triples_operator(triples,eta)\n",
    "\n",
    "oo = np.dot( U.T.dot(triples_eta).dot(V), np.linalg.inv(U.T.dot(pairs).dot(V)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
